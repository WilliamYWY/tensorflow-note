{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e847da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90372a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/yangweiyu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/yangweiyu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yangweiyu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yangweiyu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yangweiyu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25551070",
   "metadata": {},
   "source": [
    "# Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00fb113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8f6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y)) #loss function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) #choose optimizer and load loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa6c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init all var\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a6bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "for i in range(500): #epoch\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100) #generate 100 data for one epoch\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) #feed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1e8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1c06c",
   "metadata": {},
   "source": [
    "# Multi layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49c6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, output_channel, kernel, strides):\n",
    "    \"\"\"\n",
    "    input kernel size [length, width]\n",
    "    strides int\n",
    "    \"\"\"\n",
    "    #kernal size for 2d [length, width, channel, features]\n",
    "    kernel_shape = [kernel[0], kernel[1], x.get_shape()[-1].value, output_channel]\n",
    "    initial_W = tf.truncated_normal(kernel_shape, stddev=0.1) #std some what IMPORTANT\n",
    "    W = tf.Variable(initial_W)\n",
    "    \n",
    "    #Bias size = output_channel\n",
    "    initial_B = tf.constant(0.1, shape=[output_channel])\n",
    "    B = tf.Variable(initial_B)\n",
    "    #build layer + Bias\n",
    "    layer = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "    #use activation func\n",
    "    conv_act_layer = tf.nn.relu(layer + B)\n",
    "\n",
    "    return conv_act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b5d474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(x, kernel, strides):\n",
    "    \"\"\"\n",
    "    input kernel size [length, width]\n",
    "    strides int\n",
    "    \"\"\"\n",
    "    max_pool_layer = tf.nn.max_pool(x, \n",
    "                       ksize=[1, kernel[0], kernel[1], 1], \n",
    "                       strides= [1, strides, strides, 1], \n",
    "                       padding=\"SAME\")\n",
    "\n",
    "    return max_pool_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ef8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(x, output_channel):\n",
    "    # weight\n",
    "    shape = [x.get_shape()[-1].value, output_channel]\n",
    "    initial_W = tf.truncated_normal(shape, stddev=0.1) #std some what IMPORTANT\n",
    "    W = tf.Variable(initial_W)\n",
    "    #bias\n",
    "    initial_B = tf.constant(0.1, shape=[output_channel])\n",
    "    B = tf.Variable(initial_B)\n",
    "\n",
    "    layer = tf.matmul(x, W) # (W * x)\n",
    "    act_layer = tf.nn.relu(layer + B)\n",
    "\n",
    "    return act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1d049c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_layer(x, output_channel):\n",
    "    # weight\n",
    "    shape = [x.get_shape()[-1].value, output_channel]\n",
    "    initial_W = tf.truncated_normal(shape, stddev=0.1) #std some what IMPORTANT\n",
    "    W = tf.Variable(initial_W)\n",
    "    #bias\n",
    "    initial_B = tf.constant(0.1, shape=[output_channel])\n",
    "    B = tf.Variable(initial_B)\n",
    "\n",
    "    layer = tf.matmul(x, W)\n",
    "    act_layer = tf.nn.softmax(layer+B)\n",
    "\n",
    "    return act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97e14135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input placeholder\n",
    "x = tf.placeholder(dtype=\"float\", shape=[None, 784])\n",
    "input_x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "#model network\n",
    "conv2d_1 = conv2d(input_x, 32, [5,5], 1)\n",
    "max_pool1 = max_pool(conv2d_1, [2,2], 2)\n",
    "conv2d_2 = conv2d(max_pool1, 64, [5,5], 1)\n",
    "max_pool2 = max_pool(conv2d_2, [2,2], 2)\n",
    "flatten = tf.reshape(max_pool2, [-1, max_pool2.get_shape()[1]*max_pool2.get_shape()[2]*max_pool2.get_shape()[3]])\n",
    "dense_1 = dense_layer(flatten, 1024)\n",
    "output = softmax_layer(dense_1, 10) #output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf231e8",
   "metadata": {},
   "source": [
    "**Equation of cross entropy**  \n",
    "L = label  \n",
    "p = predicted probability  \n",
    "n = classes  \n",
    "$CE = \\sum_{i=1}^n -(L* \\log(p)) $\n",
    "\n",
    "hint: $(L*\\log(p))$ only the right class's probability will remain ex: $1*0.5 + 0*0.25 + 0*0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4464a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "#softmax function predict the output probability 0 to 1, can use cross entropy to evaluate the performance\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10]) #label\n",
    "cross_entropy = -1 * tf.reduce_sum(y_*tf.log(output)) #reduce_sum sum all the element\n",
    "\n",
    "#add optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "#test evaluation function (accuracy)\n",
    "#tf.argmax will out put the \"INDEX\" of maxium value (the heightest probability)\n",
    "#tf.equal will generate [True, True, False, ....] matrix\n",
    "\n",
    "acc_matrix = tf.equal(tf.argmax(output, 1), tf.argmax(y_, 1))\n",
    "\n",
    "#tf.cast will transform input to required type in here Bool to (0,1)\n",
    "#tf.reduce_mean will output the mean of matrix\n",
    "\n",
    "acc_eval = tf.reduce_mean(tf.cast(acc_matrix, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7513fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps0: ACC: 0.03999999910593033\n",
      "Steps50: ACC: 0.7799999713897705\n",
      "Steps100: ACC: 0.9200000166893005\n",
      "Steps150: ACC: 0.9200000166893005\n",
      "Steps200: ACC: 0.9399999976158142\n",
      "Steps250: ACC: 0.8399999737739563\n",
      "Steps300: ACC: 0.8999999761581421\n",
      "Steps350: ACC: 0.8999999761581421\n",
      "Steps400: ACC: 0.9599999785423279\n",
      "Steps450: ACC: 1.0\n",
      "Network ACC: 0.9532999992370605\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epoch = 500\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epoch):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        #visualize ACC every 50 epoch\n",
    "        if i % 50 == 0:\n",
    "            train_acc = acc_eval.eval(feed_dict={x: batch[0], y_:batch[1]})\n",
    "            print(f\"Steps{i}: ACC: {train_acc}\")\n",
    "        #train network\n",
    "        train_step.run(feed_dict={x: batch[0], y_:batch[1]})\n",
    "    test_acc = acc_eval.eval(feed_dict={x: mnist.test.images, y_:mnist.test.labels})\n",
    "    print(f\"Network ACC: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
